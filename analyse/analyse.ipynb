{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du processus...\n",
      "Connexion à MongoDB...\n",
      "Extraction des données de MongoDB...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 143\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessus terminé.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[9], line 128\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDébut du processus...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m     data \u001b[38;5;241m=\u001b[39m fetch_data()\n\u001b[0;32m    129\u001b[0m     df \u001b[38;5;241m=\u001b[39m prepare_data(data)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# Perform regression and generate images\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m, in \u001b[0;36mfetch_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m projection \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     31\u001b[0m }\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtraction des données de MongoDB...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(collection\u001b[38;5;241m.\u001b[39mfind({}, projection))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentrées récupérées: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m client\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\cursor.py:1264\u001b[0m, in \u001b[0;36mCursor.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__empty:\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh():\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\cursor.py:1204\u001b[0m, in \u001b[0;36mCursor._refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;66;03m# Exhaust cursors don't send getMore messages.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getmore_class(\n\u001b[0;32m   1191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__dbname,\n\u001b[0;32m   1192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__collname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__comment,\n\u001b[0;32m   1203\u001b[0m     )\n\u001b[1;32m-> 1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__send_message(g)\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data)\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\cursor.py:1060\u001b[0m, in \u001b[0;36mCursor.__send_message\u001b[1;34m(self, operation)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidOperation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexhaust cursors do not support auto encryption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1060\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_run_operation(\n\u001b[0;32m   1061\u001b[0m         operation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unpack_response, address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__address\n\u001b[0;32m   1062\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01min\u001b[39;00m _CURSOR_CLOSED_ERRORS \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__exhaust:\n\u001b[0;32m   1065\u001b[0m         \u001b[38;5;66;03m# Don't send killCursors because the cursor is already closed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\_csot.py:107\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:1394\u001b[0m, in \u001b[0;36mMongoClient._run_operation\u001b[1;34m(self, operation, unpack_res, address)\u001b[0m\n\u001b[0;32m   1389\u001b[0m     operation\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# Reset op in case of retry.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m server\u001b[38;5;241m.\u001b[39mrun_operation(\n\u001b[0;32m   1391\u001b[0m         conn, operation, read_preference, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_listeners, unpack_res\n\u001b[0;32m   1392\u001b[0m     )\n\u001b[1;32m-> 1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retryable_read(\n\u001b[0;32m   1395\u001b[0m     _cmd,\n\u001b[0;32m   1396\u001b[0m     operation\u001b[38;5;241m.\u001b[39mread_preference,\n\u001b[0;32m   1397\u001b[0m     operation\u001b[38;5;241m.\u001b[39msession,\n\u001b[0;32m   1398\u001b[0m     address\u001b[38;5;241m=\u001b[39maddress,\n\u001b[0;32m   1399\u001b[0m     retryable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(operation, message\u001b[38;5;241m.\u001b[39m_Query),\n\u001b[0;32m   1400\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:1492\u001b[0m, in \u001b[0;36mMongoClient._retryable_read\u001b[1;34m(self, func, read_pref, session, address, retryable)\u001b[0m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;66;03m# Ensure that the client supports retrying on reads and there is no session in\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;66;03m# transaction, otherwise, we will not support retry behavior for this call.\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m retryable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\n\u001b[0;32m   1490\u001b[0m     retryable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mretry_reads \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (session \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39min_transaction)\n\u001b[0;32m   1491\u001b[0m )\n\u001b[1;32m-> 1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_internal(\n\u001b[0;32m   1493\u001b[0m     func,\n\u001b[0;32m   1494\u001b[0m     session,\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1496\u001b[0m     is_read\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1497\u001b[0m     address\u001b[38;5;241m=\u001b[39maddress,\n\u001b[0;32m   1498\u001b[0m     read_pref\u001b[38;5;241m=\u001b[39mread_pref,\n\u001b[0;32m   1499\u001b[0m     retryable\u001b[38;5;241m=\u001b[39mretryable,\n\u001b[0;32m   1500\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\_csot.py:107\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:1462\u001b[0m, in \u001b[0;36mMongoClient._retry_internal\u001b[1;34m(self, func, session, bulk, is_read, address, read_pref, retryable)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;129m@_csot\u001b[39m\u001b[38;5;241m.\u001b[39mapply\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retry_internal\u001b[39m(\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1437\u001b[0m     retryable: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1438\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal retryable helper for all client transactions.\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \n\u001b[0;32m   1441\u001b[0m \u001b[38;5;124;03m    :Parameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;124;03m      Output of the calling func()\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClientConnectionRetryable(\n\u001b[0;32m   1454\u001b[0m         mongo_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1455\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   1456\u001b[0m         bulk\u001b[38;5;241m=\u001b[39mbulk,\n\u001b[0;32m   1457\u001b[0m         is_read\u001b[38;5;241m=\u001b[39mis_read,\n\u001b[0;32m   1458\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n\u001b[0;32m   1459\u001b[0m         read_pref\u001b[38;5;241m=\u001b[39mread_pref,\n\u001b[0;32m   1460\u001b[0m         address\u001b[38;5;241m=\u001b[39maddress,\n\u001b[0;32m   1461\u001b[0m         retryable\u001b[38;5;241m=\u001b[39mretryable,\n\u001b[1;32m-> 1462\u001b[0m     )\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:2315\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error(check_csot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_read \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write()\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[0;32m   2317\u001b[0m     \u001b[38;5;66;03m# The application may think the write was never attempted\u001b[39;00m\n\u001b[0;32m   2318\u001b[0m     \u001b[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;66;03m# attempt. Raise the original exception instead.\u001b[39;00m\n\u001b[0;32m   2320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:2445\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable._read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrying \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retryable:\n\u001b[0;32m   2444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n\u001b[1;32m-> 2445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server, conn, read_pref)\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:1390\u001b[0m, in \u001b[0;36mMongoClient._run_operation.<locals>._cmd\u001b[1;34m(_session, server, conn, read_preference)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cmd\u001b[39m(\n\u001b[0;32m   1384\u001b[0m     _session: Optional[ClientSession],\n\u001b[0;32m   1385\u001b[0m     server: Server,\n\u001b[0;32m   1386\u001b[0m     conn: Connection,\n\u001b[0;32m   1387\u001b[0m     read_preference: _ServerMode,\n\u001b[0;32m   1388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m   1389\u001b[0m     operation\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# Reset op in case of retry.\u001b[39;00m\n\u001b[1;32m-> 1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m server\u001b[38;5;241m.\u001b[39mrun_operation(\n\u001b[0;32m   1391\u001b[0m         conn, operation, read_preference, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_listeners, unpack_res\n\u001b[0;32m   1392\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\helpers.py:322\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\server.py:166\u001b[0m, in \u001b[0;36mServer.run_operation\u001b[1;34m(self, conn, operation, read_preference, listeners, unpack_res)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_cmd:\n\u001b[0;32m    165\u001b[0m         first \u001b[38;5;241m=\u001b[39m docs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 166\u001b[0m         operation\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39m_process_response(first, operation\u001b[38;5;241m.\u001b[39msession)\n\u001b[0;32m    167\u001b[0m         _check_command_response(first, conn\u001b[38;5;241m.\u001b[39mmax_wire_version)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\atdf2\\anaconda3\\Lib\\site-packages\\pymongo\\mongo_client.py:1873\u001b[0m, in \u001b[0;36mMongoClient._process_response\u001b[1;34m(self, reply, session)\u001b[0m\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cluster_time:\n\u001b[0;32m   1871\u001b[0m         command[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$clusterTime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cluster_time\n\u001b[1;32m-> 1873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, reply: Mapping[\u001b[38;5;28mstr\u001b[39m, Any], session: Optional[ClientSession]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1874\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_topology\u001b[38;5;241m.\u001b[39mreceive_cluster_time(reply\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$clusterTime\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "# MongoDB connection URI and Database\n",
    "uri = \"mongodb://127.0.0.1:27017\"\n",
    "db_name = \"tp_KBO\"\n",
    "collection_name = \"enterprises\"\n",
    "gif_output_path = \"regression_animation1.gif\"  # Path to save the GIF\n",
    "temp_image_folder = \"temp_images\"  # Temporary folder to store images\n",
    "\n",
    "# Connect to MongoDB and fetch data\n",
    "def fetch_data():\n",
    "    print(\"Connexion à MongoDB...\")\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    \n",
    "    projection = {\n",
    "        \"entity_number\": 1,\n",
    "        \"status\": 1,\n",
    "        \"start_date\": 1,\n",
    "        \"activities.nace_description\": 1,\n",
    "        \"establishments.activities.nace_description\": 1,  # Include activities from establishments\n",
    "        \"_id\": 0\n",
    "    }\n",
    "    \n",
    "    print(\"Extraction des données de MongoDB...\")\n",
    "    data = list(collection.find({}, projection))\n",
    "    print(f\"Nombre d'entrées récupérées: {len(data)}\")\n",
    "    client.close()\n",
    "    print(\"Connexion à MongoDB fermée.\")\n",
    "    return data\n",
    "\n",
    "# Prepare the data for analysis\n",
    "def prepare_data(data):\n",
    "    print(\"Préparation des données pour l'analyse...\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
    "    df['year'] = df['start_date'].dt.year\n",
    "    df = df.dropna(subset=['year'])\n",
    "    df['year'] = df['year'].astype(int)\n",
    "\n",
    "    def count_activities(activities, establishments):\n",
    "        activity_count = len(activities) if isinstance(activities, list) else 0\n",
    "        if isinstance(establishments, list):\n",
    "            for est in establishments:\n",
    "                activity_count += len(est.get('activities', []))\n",
    "        return activity_count\n",
    "\n",
    "    df['activity_count'] = df.apply(lambda row: count_activities(row.get('activities', []), row.get('establishments', [])), axis=1)\n",
    "    print(f\"Données préparées avec succès. Nombre d'entrées valides: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Perform linear regression by year\n",
    "def perform_regression(df):\n",
    "    print(\"Réalisation de la régression linéaire progressive par année...\")\n",
    "    # List to store images for the GIF\n",
    "    images = []\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.exists(temp_image_folder):\n",
    "        os.makedirs(temp_image_folder)\n",
    "\n",
    "    # Sort data by year and iterate year by year\n",
    "    df_sorted = df.sort_values(by='year')\n",
    "    unique_years = df_sorted['year'].unique()\n",
    "\n",
    "    for i, year in enumerate(unique_years, start=1):\n",
    "        # Filter data up to the current year\n",
    "        df_current = df_sorted[df_sorted['year'] <= year]\n",
    "        X = df_current['year'].values.reshape(-1, 1)\n",
    "        y = df_current['activity_count'].values\n",
    "        \n",
    "        # Create linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "        # Generate image for the current year\n",
    "        image_path = os.path.join(temp_image_folder, f\"frame_{year}.png\")\n",
    "        plot_progress(X, y, y_pred, model.coef_[0], model.intercept_, year, image_path)\n",
    "        images.append(image_path)\n",
    "\n",
    "    print(f\"Régression terminée après {len(unique_years)} années.\")\n",
    "    return images\n",
    "\n",
    "# Plot the results and save each frame as an image\n",
    "def plot_progress(X, y, y_pred, slope, intercept, year, image_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X, y, color=\"blue\", label=\"Données réelles\")\n",
    "    plt.plot(X, y_pred, color=\"red\", linewidth=2, label=f\"Régression linéaire: y = {slope:.2f}x + {intercept:.2f}\")\n",
    "    \n",
    "    plt.title(f\"Régression du nombre d'activités jusqu'à l'année {year}\")\n",
    "    plt.xlabel(\"Année\")\n",
    "    plt.ylabel(\"Nombre d'activités\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n",
    "    print(f\"Image sauvegardée pour l'année {year}: {image_path}\")\n",
    "\n",
    "# Combine all the images into a GIF\n",
    "def create_gif(image_paths, gif_output_path):\n",
    "    print(\"Création du GIF...\")\n",
    "    images = [imageio.imread(image_path) for image_path in image_paths]\n",
    "    imageio.mimsave(gif_output_path, images, duration=0.5)\n",
    "    print(f\"GIF sauvegardé sous {gif_output_path}\")\n",
    "\n",
    "# Clean up temporary images after GIF creation\n",
    "def cleanup_images(image_paths):\n",
    "    print(\"Nettoyage des images temporaires...\")\n",
    "    for image_path in image_paths:\n",
    "        os.remove(image_path)\n",
    "    if os.path.exists(temp_image_folder):\n",
    "        os.rmdir(temp_image_folder)\n",
    "    print(\"Images temporaires supprimées.\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    print(\"Début du processus...\")\n",
    "    \n",
    "    data = fetch_data()\n",
    "    df = prepare_data(data)\n",
    "    \n",
    "    # Perform regression and generate images\n",
    "    image_paths = perform_regression(df)\n",
    "    \n",
    "    # Create GIF from images\n",
    "    create_gif(image_paths, gif_output_path)\n",
    "    \n",
    "    # Cleanup temporary images\n",
    "    cleanup_images(image_paths)\n",
    "    \n",
    "    print(\"Processus terminé.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du processus...\n",
      "Connexion à MongoDB...\n",
      "Extraction des données de MongoDB...\n",
      "Nombre d'entrées récupérées: 1890258\n",
      "Connexion à MongoDB fermée.\n",
      "Préparation des données pour l'analyse...\n",
      "Données préparées avec succès. Nombre d'années : 175\n",
      "Réalisation de la régression linéaire...\n",
      "Régression terminée. Pente: 295.47, Ordonnée à l'origine: -559526.83\n",
      "Coefficient de détermination (R²): 0.34\n",
      "Root Mean Squared Error (RMSE): 22973.27\n",
      "Création des frames pour le GIF...\n",
      "Frames sauvegardées dans le dossier 'frames/'.\n",
      "Création du GIF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atdf2\\AppData\\Local\\Temp\\ipykernel_18632\\957366286.py:135: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(file_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF créé avec succès: regression_animation.gif\n",
      "Processus terminé.\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "# MongoDB connection URI and Database\n",
    "uri = \"mongodb://127.0.0.1:27017\"\n",
    "db_name = \"tp_KBO\"\n",
    "collection_name = \"enterprises\"\n",
    "\n",
    "# Directory for saving frames\n",
    "frames_dir = \"frames/\"\n",
    "gif_filename = \"regression_animation.gif\"\n",
    "\n",
    "# Connect to MongoDB and fetch data\n",
    "def fetch_data():\n",
    "    print(\"Connexion à MongoDB...\")\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    \n",
    "    # Projection to retrieve only relevant fields\n",
    "    projection = {\n",
    "        \"entity_number\": 1,\n",
    "        \"status\": 1,\n",
    "        \"start_date\": 1,\n",
    "        \"activities.nace_description\": 1,\n",
    "        \"_id\": 0\n",
    "    }\n",
    "    \n",
    "    print(\"Extraction des données de MongoDB...\")\n",
    "    data = list(collection.find({}, projection))\n",
    "    print(f\"Nombre d'entrées récupérées: {len(data)}\")\n",
    "    client.close()\n",
    "    print(\"Connexion à MongoDB fermée.\")\n",
    "    return data\n",
    "\n",
    "# Prepare the data for analysis\n",
    "def prepare_data(data):\n",
    "    print(\"Préparation des données pour l'analyse...\")\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert start_date to datetime and extract the year\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
    "    df['year'] = df['start_date'].dt.year\n",
    "\n",
    "    # Filter rows where year is not NaN\n",
    "    df = df.dropna(subset=['year'])\n",
    "    \n",
    "    # Convert year to numeric values (independent variable)\n",
    "    df['year'] = df['year'].astype(int)\n",
    "\n",
    "    # Calculate the number of activities per enterprise per year\n",
    "    df['activity_count'] = df['activities'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "    # Group by year to calculate total number of activities per year\n",
    "    df_grouped = df.groupby('year')['activity_count'].sum().reset_index()\n",
    "\n",
    "    print(f\"Données préparées avec succès. Nombre d'années : {len(df_grouped)}\")\n",
    "    return df_grouped\n",
    "\n",
    "# Perform linear regression\n",
    "def perform_regression(df):\n",
    "    print(\"Réalisation de la régression linéaire...\")\n",
    "    X = df['year'].values.reshape(-1, 1)  # Independent variable\n",
    "    y = df['activity_count'].values  # Dependent variable\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    y_pred = model.predict(X)  # Predictions\n",
    "    \n",
    "    slope = model.coef_[0]  # Slope\n",
    "    intercept = model.intercept_  # Intercept\n",
    "    \n",
    "    # Calculate R² and RMSE\n",
    "    r_squared = r2_score(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    \n",
    "    print(f\"Régression terminée. Pente: {slope:.2f}, Ordonnée à l'origine: {intercept:.2f}\")\n",
    "    print(f\"Coefficient de détermination (R²): {r_squared:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    \n",
    "    return X, y, y_pred, slope, intercept, r_squared, rmse\n",
    "\n",
    "# Save each frame of the regression as an image\n",
    "def save_frames(X, y, y_pred, slope, intercept, r_squared, rmse):\n",
    "    print(\"Création des frames pour le GIF...\")\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.makedirs(frames_dir)\n",
    "\n",
    "    # Complete line for regression (based on the entire dataset)\n",
    "    y_pred_complete = slope * X + intercept\n",
    "\n",
    "    for i in range(1, len(X) + 1):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot all the real data points\n",
    "        plt.scatter(X, y, color=\"blue\", label=\"Données réelles\")\n",
    "\n",
    "        # Plot the partial regression line\n",
    "        plt.plot(X[:i], y_pred[:i], color=\"red\", linewidth=2, label=f\"Régression partielle: y = {slope:.2f}x + {intercept:.2f}\")\n",
    "        \n",
    "        # Plot the full regression line\n",
    "        plt.plot(X, y_pred_complete, color=\"green\", linestyle=\"--\", label=\"Ligne complète de régression\")\n",
    "\n",
    "        plt.title(\"Régression du nombre total d'activités par année\")\n",
    "        plt.xlabel(\"Année\")\n",
    "        plt.ylabel(\"Nombre total d'activités\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Show R² and RMSE on each frame\n",
    "        plt.text(0.05, 0.95, f\"R²: {r_squared:.2f}\\nRMSE: {rmse:.2f}\", transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n",
    "        \n",
    "        # Save each frame as an image\n",
    "        frame_path = os.path.join(frames_dir, f\"frame_{i:03d}.png\")\n",
    "        plt.savefig(frame_path)\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"Frames sauvegardées dans le dossier '{frames_dir}'.\")\n",
    "\n",
    "# Create a GIF from the saved frames\n",
    "def create_gif():\n",
    "    print(\"Création du GIF...\")\n",
    "    images = []\n",
    "    for file_name in sorted(os.listdir(frames_dir)):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(frames_dir, file_name)\n",
    "            images.append(imageio.imread(file_path))\n",
    "    \n",
    "    imageio.mimsave(gif_filename, images, fps=2)\n",
    "    print(f\"GIF créé avec succès: {gif_filename}\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    print(\"Début du processus...\")\n",
    "    \n",
    "    # Fetch data from MongoDB\n",
    "    data = fetch_data()\n",
    "    \n",
    "    # Prepare data for regression\n",
    "    df_grouped = prepare_data(data)\n",
    "    \n",
    "    # Perform regression\n",
    "    X, y, y_pred, slope, intercept, r_squared, rmse = perform_regression(df_grouped)\n",
    "    \n",
    "    # Save frames for the GIF\n",
    "    save_frames(X, y, y_pred, slope, intercept, r_squared, rmse)\n",
    "    \n",
    "    # Create GIF from saved frames\n",
    "    create_gif()\n",
    "    \n",
    "    print(\"Processus terminé.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du processus d'analyse des tendances des groupes d'activités...\n",
      "Connexion à MongoDB...\n",
      "Extraction des données de MongoDB...\n",
      "Nombre d'entrées récupérées: 1890258\n",
      "Préparation des données pour l'analyse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atdf2\\AppData\\Local\\Temp\\ipykernel_22616\\546181240.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['year'] = df['year'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'entrées après préparation: 2097252\n",
      "Analyse des tendances des groupes d'activités...\n",
      "Création des frames pour chaque année...\n",
      "Frames sauvegardées dans le dossier 'frames'.\n",
      "Création du GIF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atdf2\\AppData\\Local\\Temp\\ipykernel_22616\\546181240.py:118: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(file_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF créé avec succès: activity_group_trends.gif\n",
      "Nettoyage des frames temporaires...\n",
      "Frames temporaires supprimées.\n",
      "Processus terminé.\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# MongoDB connection URI and Database\n",
    "uri = \"mongodb://127.0.0.1:27017\"\n",
    "db_name = \"tp_KBO\"\n",
    "collection_name = \"enterprises\"\n",
    "\n",
    "# Dossier pour enregistrer les images temporaires\n",
    "frames_dir = \"frames\"\n",
    "gif_filename = \"activity_group_trends.gif\"\n",
    "\n",
    "# Connexion à MongoDB et extraction des données\n",
    "def fetch_data():\n",
    "    print(\"Connexion à MongoDB...\")\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Projeter uniquement les champs pertinents\n",
    "    projection = {\n",
    "        \"entity_number\": 1,\n",
    "        \"start_date\": 1,\n",
    "        \"activities.activity_group\": 1,  # Groupes d'activités\n",
    "        \"_id\": 0\n",
    "    }\n",
    "    \n",
    "    print(\"Extraction des données de MongoDB...\")\n",
    "    data = list(collection.find({}, projection))\n",
    "    client.close()\n",
    "    print(f\"Nombre d'entrées récupérées: {len(data)}\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Préparation des données pour l'analyse\n",
    "def prepare_data(df):\n",
    "    print(\"Préparation des données pour l'analyse...\")\n",
    "    \n",
    "    # Convertir start_date en datetime et extraire l'année\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
    "    df['year'] = df['start_date'].dt.year\n",
    "    \n",
    "    # Filtrer les lignes sans date valide\n",
    "    df = df.dropna(subset=['year'])\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    \n",
    "    # Exploser les listes de `activity_group` pour avoir une ligne par groupe d'activité\n",
    "    df = df.explode('activities')\n",
    "    \n",
    "    # Filtrer uniquement les entrées qui ont un groupe d'activités valide\n",
    "    df = df[df['activities'].notnull()]\n",
    "    \n",
    "    # Extraire le groupe d'activités\n",
    "    df['activity_group'] = df['activities'].apply(lambda x: x.get('activity_group') if isinstance(x, dict) else None)\n",
    "    \n",
    "    # Filtrer les lignes sans `activity_group`\n",
    "    df = df.dropna(subset=['activity_group'])\n",
    "    \n",
    "    print(f\"Nombre d'entrées après préparation: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Compter les occurrences des groupes d'activités par année\n",
    "def analyze_activity_group_trends(df):\n",
    "    print(\"Analyse des tendances des groupes d'activités...\")\n",
    "    \n",
    "    # Compter le nombre de fois que chaque `activity_group` apparaît pour chaque année\n",
    "    activity_trend = df.groupby(['year', 'activity_group']).size().reset_index(name='count')\n",
    "    \n",
    "    # Filtrer pour garder les 10 groupes d'activités les plus fréquents\n",
    "    top_activity_groups = activity_trend.groupby('activity_group')['count'].sum().nlargest(10).index\n",
    "    top_activity_trend = activity_trend[activity_trend['activity_group'].isin(top_activity_groups)]\n",
    "    \n",
    "    return top_activity_trend\n",
    "\n",
    "# Créer et enregistrer un graphique pour chaque année\n",
    "def save_frames_by_year(activity_trend):\n",
    "    print(\"Création des frames pour chaque année...\")\n",
    "    \n",
    "    # Créer un dossier pour enregistrer les frames\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.makedirs(frames_dir)\n",
    "\n",
    "    # Générer un graphique pour chaque année de manière cumulative et enregistrer les images\n",
    "    years = sorted(activity_trend['year'].unique())\n",
    "    for year in years:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Filtrer les données cumulatives jusqu'à l'année courante\n",
    "        cumulative_data = activity_trend[activity_trend['year'] <= year]\n",
    "        \n",
    "        sns.lineplot(data=cumulative_data, x='year', y='count', hue='activity_group', marker='o')\n",
    "\n",
    "        plt.title(f\"Tendances des groupes d'activités jusqu'à {year}\")\n",
    "        plt.xlabel(\"Année\")\n",
    "        plt.ylabel(\"Nombre d'occurrences du groupe d'activité\")\n",
    "        plt.legend(title=\"Groupe d'activités\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Enregistrer l'image pour cette année\n",
    "        frame_filename = os.path.join(frames_dir, f\"frame_{year}.png\")\n",
    "        plt.savefig(frame_filename)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Frames sauvegardées dans le dossier '{frames_dir}'.\")\n",
    "\n",
    "# Créer un GIF à partir des frames enregistrées\n",
    "def create_gif():\n",
    "    print(\"Création du GIF...\")\n",
    "    images = []\n",
    "    for file_name in sorted(os.listdir(frames_dir)):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(frames_dir, file_name)\n",
    "            images.append(imageio.imread(file_path))\n",
    "\n",
    "    imageio.mimsave(gif_filename, images, fps=2)\n",
    "    print(f\"GIF créé avec succès: {gif_filename}\")\n",
    "\n",
    "# Supprimer les frames temporaires\n",
    "def cleanup_frames():\n",
    "    print(\"Nettoyage des frames temporaires...\")\n",
    "    for file_name in os.listdir(frames_dir):\n",
    "        file_path = os.path.join(frames_dir, file_name)\n",
    "        os.remove(file_path)\n",
    "    os.rmdir(frames_dir)\n",
    "    print(\"Frames temporaires supprimées.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Début du processus d'analyse des tendances des groupes d'activités...\")\n",
    "\n",
    "    # Étape 1 : Récupérer les données de MongoDB\n",
    "    data = fetch_data()\n",
    "\n",
    "    # Étape 2 : Préparer les données\n",
    "    df_prepared = prepare_data(data)\n",
    "\n",
    "    # Étape 3 : Analyser les tendances des groupes d'activités\n",
    "    activity_trend = analyze_activity_group_trends(df_prepared)\n",
    "\n",
    "    # Étape 4 : Sauvegarder les frames par année\n",
    "    save_frames_by_year(activity_trend)\n",
    "\n",
    "    # Étape 5 : Créer le GIF\n",
    "    create_gif()\n",
    "\n",
    "    # Étape 6 : Nettoyer les frames temporaires\n",
    "    cleanup_frames()\n",
    "\n",
    "    print(\"Processus terminé.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du processus d'analyse des tendances des activités par code postal...\n",
      "Connexion à MongoDB...\n",
      "Extraction des données de MongoDB...\n",
      "Nombre d'entrées récupérées: 1890258\n",
      "Préparation des données pour l'analyse...\n",
      "Nombre d'entrées après préparation: 969879\n",
      "Regroupement des années par périodes de 50 ans...\n",
      "Analyse des tendances des activités par code postal...\n",
      "Création des frames pour chaque période...\n",
      "Frames sauvegardées dans le dossier 'frames_postal_bar'.\n",
      "Création du GIF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atdf2\\AppData\\Local\\Temp\\ipykernel_22060\\3873807023.py:131: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(file_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF créé avec succès: activity_trends_bar_by_postal_code.gif\n",
      "Nettoyage des frames temporaires...\n",
      "Frames temporaires supprimées.\n",
      "Processus terminé.\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# MongoDB connection URI and Database\n",
    "uri = \"mongodb://127.0.0.1:27017\"\n",
    "db_name = \"tp_KBO\"\n",
    "collection_name = \"enterprises\"\n",
    "\n",
    "# Dossier pour enregistrer les images temporaires\n",
    "frames_dir = \"frames_postal_bar\"\n",
    "gif_filename = \"activity_trends_bar_by_postal_code.gif\"\n",
    "\n",
    "# Connexion à MongoDB et extraction des données\n",
    "def fetch_data():\n",
    "    print(\"Connexion à MongoDB...\")\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Projeter uniquement les champs pertinents des établissements\n",
    "    projection = {\n",
    "        \"entity_number\": 1,\n",
    "        \"establishments.start_date\": 1,  # Date de démarrage des établissements\n",
    "        \"establishments.addresses.zipcode\": 1,  # Code postal des établissements\n",
    "        \"establishments.activities.activity_group\": 1,  # Groupes d'activités des établissements\n",
    "        \"_id\": 0\n",
    "    }\n",
    "    \n",
    "    print(\"Extraction des données de MongoDB...\")\n",
    "    data = list(collection.find({}, projection))\n",
    "    client.close()\n",
    "    print(f\"Nombre d'entrées récupérées: {len(data)}\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Préparation des données pour l'analyse\n",
    "def prepare_data(df):\n",
    "    print(\"Préparation des données pour l'analyse...\")\n",
    "    \n",
    "    # Exploser les listes d'établissements pour avoir une ligne par établissement\n",
    "    df = df.explode('establishments')\n",
    "\n",
    "    # Convertir establishments.start_date en datetime et extraire l'année\n",
    "    df['establishment_start_date'] = df['establishments'].apply(lambda x: x.get('start_date') if isinstance(x, dict) else None)\n",
    "    df['establishment_start_date'] = pd.to_datetime(df['establishment_start_date'], errors='coerce')\n",
    "    df['year'] = df['establishment_start_date'].dt.year\n",
    "    \n",
    "    # Filtrer les lignes sans date valide\n",
    "    df = df.dropna(subset=['year'])\n",
    "    df['year'] = df['year'].astype(int)\n",
    "\n",
    "    # Extraire les activités et les adresses des établissements en vérifiant si les listes ne sont pas vides\n",
    "    df['activity_group'] = df['establishments'].apply(\n",
    "        lambda x: x.get('activities', [{}])[0].get('activity_group') if isinstance(x, dict) and len(x.get('activities', [])) > 0 else None\n",
    "    )\n",
    "    df['zipcode'] = df['establishments'].apply(\n",
    "        lambda x: x.get('addresses', [{}])[0].get('zipcode') if isinstance(x, dict) and len(x.get('addresses', [])) > 0 else None\n",
    "    )\n",
    "    \n",
    "    # Filtrer les lignes sans `activity_group` ou `zipcode`\n",
    "    df = df.dropna(subset=['activity_group', 'zipcode'])\n",
    "    \n",
    "    print(f\"Nombre d'entrées après préparation: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Regrouper les années en périodes de 50 ans\n",
    "def group_years_by_period(df):\n",
    "    print(\"Regroupement des années par périodes de 50 ans...\")\n",
    "    \n",
    "    df['period'] = (df['year'] // 50) * 50  # Créer des périodes de 50 ans\n",
    "    return df\n",
    "\n",
    "# Compter les occurrences des groupes d'activités par code postal et période\n",
    "def analyze_activity_trends_by_postal(df):\n",
    "    print(\"Analyse des tendances des activités par code postal...\")\n",
    "\n",
    "    # Compter le nombre d'occurrences de chaque `activity_group` par code postal et par période\n",
    "    activity_trend = df.groupby(['period', 'zipcode', 'activity_group']).size().reset_index(name='count')\n",
    "\n",
    "    # Filtrer pour garder les 10 codes postaux les plus actifs\n",
    "    top_postal_codes = activity_trend.groupby('zipcode')['count'].sum().nlargest(10).index\n",
    "\n",
    "    # Regrouper les autres codes postaux sous 'Autres'\n",
    "    activity_trend['zipcode_group'] = activity_trend['zipcode'].apply(lambda x: x if x in top_postal_codes else 'Autres')\n",
    "\n",
    "    return activity_trend\n",
    "\n",
    "# Créer et enregistrer un graphique à barres pour chaque période\n",
    "def save_frames_by_period(activity_trend):\n",
    "    print(\"Création des frames pour chaque période...\")\n",
    "\n",
    "    # Créer un dossier pour enregistrer les frames\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.makedirs(frames_dir)\n",
    "\n",
    "    # Générer un diagramme à barres pour chaque période et enregistrer les images\n",
    "    periods = sorted(activity_trend['period'].unique())\n",
    "    for period in periods:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Filtrer les données pour la période courante\n",
    "        period_data = activity_trend[activity_trend['period'] == period]\n",
    "\n",
    "        sns.barplot(data=period_data, x='zipcode_group', y='count', hue='activity_group', dodge=False, palette=\"muted\")\n",
    "        \n",
    "        plt.title(f\"Tendances des activités par code postal pour la période {period} - {period + 49}\")\n",
    "        plt.xlabel(\"Code Postal\")\n",
    "        plt.ylabel(\"Nombre d'occurrences d'activités\")\n",
    "        plt.legend(title=\"Groupe d'activités\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Enregistrer l'image pour cette période\n",
    "        frame_filename = os.path.join(frames_dir, f\"frame_{period}.png\")\n",
    "        plt.savefig(frame_filename)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Frames sauvegardées dans le dossier '{frames_dir}'.\")\n",
    "\n",
    "# Créer un GIF à partir des frames enregistrées\n",
    "def create_gif():\n",
    "    print(\"Création du GIF...\")\n",
    "    images = []\n",
    "    for file_name in sorted(os.listdir(frames_dir)):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(frames_dir, file_name)\n",
    "            images.append(imageio.imread(file_path))\n",
    "\n",
    "    imageio.mimsave(gif_filename, images, fps=0.3)\n",
    "    print(f\"GIF créé avec succès: {gif_filename}\")\n",
    "\n",
    "# Supprimer les frames temporaires\n",
    "def cleanup_frames():\n",
    "    print(\"Nettoyage des frames temporaires...\")\n",
    "    for file_name in os.listdir(frames_dir):\n",
    "        file_path = os.path.join(frames_dir, file_name)\n",
    "        os.remove(file_path)\n",
    "    os.rmdir(frames_dir)\n",
    "    print(\"Frames temporaires supprimées.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Début du processus d'analyse des tendances des activités par code postal...\")\n",
    "\n",
    "    # Étape 1 : Récupérer les données de MongoDB\n",
    "    data = fetch_data()\n",
    "\n",
    "    # Étape 2 : Préparer les données\n",
    "    df_prepared = prepare_data(data)\n",
    "\n",
    "    # Étape 3 : Regrouper les années en périodes de 50 ans\n",
    "    df_grouped = group_years_by_period(df_prepared)\n",
    "\n",
    "    # Étape 4 : Analyser les tendances des activités par code postal\n",
    "    activity_trend = analyze_activity_trends_by_postal(df_grouped)\n",
    "\n",
    "    # Étape 5 : Sauvegarder les frames par période\n",
    "    save_frames_by_period(activity_trend)\n",
    "\n",
    "    # Étape 6 : Créer le GIF\n",
    "    create_gif()\n",
    "\n",
    "    # Étape 7 : Nettoyer les frames temporaires\n",
    "    cleanup_frames()\n",
    "\n",
    "    print(\"Processus terminé.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du processus d'analyse des tendances des activités par code postal...\n",
      "Connexion à MongoDB...\n",
      "Extraction des données de MongoDB...\n",
      "Nombre d'entrées récupérées: 1890258\n",
      "Préparation des données pour l'analyse...\n",
      "Nombre d'entrées après préparation: 969879\n",
      "Analyse des tendances des activités par code postal...\n",
      "Création des frames pour chaque année...\n",
      "Frames sauvegardées dans le dossier 'frames_postal'.\n",
      "Création du GIF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atdf2\\AppData\\Local\\Temp\\ipykernel_22060\\1020227339.py:123: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(file_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF créé avec succès: activity_trends_by_postal_code.gif\n",
      "Nettoyage des frames temporaires...\n",
      "Frames temporaires supprimées.\n",
      "Processus terminé.\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# MongoDB connection URI and Database\n",
    "uri = \"mongodb://127.0.0.1:27017\"\n",
    "db_name = \"tp_KBO\"\n",
    "collection_name = \"enterprises\"\n",
    "\n",
    "# Dossier pour enregistrer les images temporaires\n",
    "frames_dir = \"frames_postal\"\n",
    "gif_filename = \"activity_trends_by_postal_code.gif\"\n",
    "\n",
    "# Connexion à MongoDB et extraction des données\n",
    "def fetch_data():\n",
    "    print(\"Connexion à MongoDB...\")\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Projeter uniquement les champs pertinents des établissements, y compris leur date de démarrage\n",
    "    projection = {\n",
    "        \"entity_number\": 1,\n",
    "        \"establishments.start_date\": 1,  # Date de démarrage des établissements\n",
    "        \"establishments.addresses.zipcode\": 1,  # Code postal des établissements\n",
    "        \"establishments.activities.activity_group\": 1,  # Groupes d'activités des établissements\n",
    "        \"_id\": 0\n",
    "    }\n",
    "    \n",
    "    print(\"Extraction des données de MongoDB...\")\n",
    "    data = list(collection.find({}, projection))\n",
    "    client.close()\n",
    "    print(f\"Nombre d'entrées récupérées: {len(data)}\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Préparation des données pour l'analyse\n",
    "def prepare_data(df):\n",
    "    print(\"Préparation des données pour l'analyse...\")\n",
    "    \n",
    "    # Exploser les listes d'établissements pour avoir une ligne par activité et par adresse\n",
    "    df = df.explode('establishments')\n",
    "\n",
    "    # Convertir establishments.start_date en datetime et extraire l'année\n",
    "    df['establishment_start_date'] = df['establishments'].apply(lambda x: x.get('start_date') if isinstance(x, dict) else None)\n",
    "    df['establishment_start_date'] = pd.to_datetime(df['establishment_start_date'], errors='coerce')\n",
    "    df['year'] = df['establishment_start_date'].dt.year\n",
    "    \n",
    "    # Filtrer les lignes sans date valide\n",
    "    df = df.dropna(subset=['year'])\n",
    "    df['year'] = df['year'].astype(int)\n",
    "\n",
    "    # Extraire les activités et les adresses des établissements en vérifiant si les listes ne sont pas vides\n",
    "    df['activity_group'] = df['establishments'].apply(\n",
    "        lambda x: x.get('activities', [{}])[0].get('activity_group') if isinstance(x, dict) and len(x.get('activities', [])) > 0 else None\n",
    "    )\n",
    "    df['zipcode'] = df['establishments'].apply(\n",
    "        lambda x: x.get('addresses', [{}])[0].get('zipcode') if isinstance(x, dict) and len(x.get('addresses', [])) > 0 else None\n",
    "    )\n",
    "    \n",
    "    # Filtrer les lignes sans `activity_group` ou `zipcode`\n",
    "    df = df.dropna(subset=['activity_group', 'zipcode'])\n",
    "    \n",
    "    print(f\"Nombre d'entrées après préparation: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Compter les occurrences des groupes d'activités par code postal et année\n",
    "def analyze_activity_trends_by_postal(df):\n",
    "    print(\"Analyse des tendances des activités par code postal...\")\n",
    "    \n",
    "    # Compter le nombre d'occurrences de chaque `activity_group` par code postal et par année\n",
    "    activity_trend = df.groupby(['year', 'zipcode', 'activity_group']).size().reset_index(name='count')\n",
    "    \n",
    "    # Filtrer pour garder les 10 codes postaux les plus actifs\n",
    "    top_postal_codes = activity_trend.groupby('zipcode')['count'].sum().nlargest(10).index\n",
    "    activity_trend['zipcode_group'] = activity_trend['zipcode'].apply(lambda x: x if x in top_postal_codes else 'Autres')\n",
    "    \n",
    "    return activity_trend\n",
    "\n",
    "# Créer et enregistrer un graphique pour chaque année\n",
    "def save_frames_by_year(activity_trend):\n",
    "    print(\"Création des frames pour chaque année...\")\n",
    "    \n",
    "    # Créer un dossier pour enregistrer les frames\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.makedirs(frames_dir)\n",
    "\n",
    "    # Générer un graphique pour chaque année de manière cumulative et enregistrer les images\n",
    "    years = sorted(activity_trend['year'].unique())\n",
    "    for year in years:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        # Filtrer les données cumulatives jusqu'à l'année courante\n",
    "        cumulative_data = activity_trend[activity_trend['year'] <= year]\n",
    "        \n",
    "        # Tracer les lignes pour chaque groupe de codes postaux\n",
    "        sns.lineplot(data=cumulative_data, x='year', y='count', hue='zipcode_group', marker='o', palette='tab10')\n",
    "        \n",
    "        plt.title(f\"Tendances des activités par code postal jusqu'à {year}\", fontsize=16)\n",
    "        plt.xlabel(\"Année\", fontsize=14)\n",
    "        plt.ylabel(\"Nombre d'occurrences d'activités\", fontsize=14)\n",
    "        plt.legend(title=\"Code Postal\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Enregistrer l'image pour cette année\n",
    "        frame_filename = os.path.join(frames_dir, f\"frame_{year}.png\")\n",
    "        plt.savefig(frame_filename)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Frames sauvegardées dans le dossier '{frames_dir}'.\")\n",
    "\n",
    "# Créer un GIF à partir des frames enregistrées\n",
    "def create_gif():\n",
    "    print(\"Création du GIF...\")\n",
    "    images = []\n",
    "    for file_name in sorted(os.listdir(frames_dir)):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(frames_dir, file_name)\n",
    "            images.append(imageio.imread(file_path))\n",
    "\n",
    "    imageio.mimsave(gif_filename, images, fps=2)\n",
    "    print(f\"GIF créé avec succès: {gif_filename}\")\n",
    "\n",
    "# Supprimer les frames temporaires\n",
    "def cleanup_frames():\n",
    "    print(\"Nettoyage des frames temporaires...\")\n",
    "    for file_name in os.listdir(frames_dir):\n",
    "        file_path = os.path.join(frames_dir, file_name)\n",
    "        os.remove(file_path)\n",
    "    os.rmdir(frames_dir)\n",
    "    print(\"Frames temporaires supprimées.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Début du processus d'analyse des tendances des activités par code postal...\")\n",
    "\n",
    "    # Étape 1 : Récupérer les données de MongoDB\n",
    "    data = fetch_data()\n",
    "\n",
    "    # Étape 2 : Préparer les données\n",
    "    df_prepared = prepare_data(data)\n",
    "\n",
    "    # Étape 3 : Analyser les tendances des activités par code postal\n",
    "    activity_trend = analyze_activity_trends_by_postal(df_prepared)\n",
    "\n",
    "    # Étape 4 : Sauvegarder les frames par année\n",
    "    save_frames_by_year(activity_trend)\n",
    "\n",
    "    # Étape 5 : Créer le GIF\n",
    "    create_gif()\n",
    "\n",
    "    # Étape 6 : Nettoyer les frames temporaires\n",
    "    cleanup_frames()\n",
    "\n",
    "    print(\"Processus terminé.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
